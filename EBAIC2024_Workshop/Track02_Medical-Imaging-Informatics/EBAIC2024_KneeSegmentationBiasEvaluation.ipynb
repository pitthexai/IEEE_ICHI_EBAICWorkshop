{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN5k5IvrWdDJTaB9Fjh0N5z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pitthexai/ICHI2023_EBAIC/blob/main/EBAIC2024_Workshop/Track02_Medical-Imaging-Informatics/EBAIC2024_KneeSegmentationBiasEvaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EBAIC 2024 Track II: Medical Imaging Informatics: Fair Knee Anatomy Segmentation\n",
        "\n",
        "AI fairness in medical image analysis is a critical aspect in the development of fair AI and deep learning models in healthcare settings. For instance, an accurate and reliable segmentation of medical images is essential for precise disease diagnosis, personalized treatment planning, and effective patient monitoring. However, when fairness is not adequately addressed, these AI models can inadvertently perpetuate biases and disparities in healthcare delivery. Fairness in medical image segmentation ensures that the AI algorithms do not discriminate against individuals based on their race, gender, socioeconomic status, or any other demographic factors. It aims to provide equitable healthcare outcomes for all patients, irrespective of their background or characteristics.\n",
        "\n",
        "Upholding fairness in AI models for medical image segmentation is not only an ethical imperative but also crucial for building trust in AI systems within the medical community and among patients. Transparent and accountable AI algorithms, coupled with comprehensive data collection and evaluation, can help identify and rectify biases present in the training data or the algorithmic decision-making process. This iterative process of refinement and evaluation ensures that AI models produce consistent and equitable results, contributing to the overall quality and fairness of healthcare delivery.\n"
      ],
      "metadata": {
        "id": "c9FKzHsdt53U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Package Setup"
      ],
      "metadata": {
        "id": "JcB5b0PHRgW8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s93SFhrOrxTa"
      },
      "outputs": [],
      "source": [
        "!pip install segmentation-models-pytorch albumentations torchmetrics pydicom nibabel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import copy\n",
        "\n",
        "from zipfile import ZipFile\n",
        "\n",
        "from io import BytesIO\n",
        "from gzip import GzipFile\n",
        "\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "import pydicom\n",
        "import nibabel\n",
        "from nibabel import FileHolder, Nifti1Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "from segmentation_models_pytorch import utils as smp_utils\n",
        "\n",
        "from torchmetrics.classification import MulticlassJaccardIndex, Dice\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Pd3G4QOJs0KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yevZb-zWr5HB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_STATE = 42"
      ],
      "metadata": {
        "id": "Hqi8DEP2sI34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Data Preprocessing"
      ],
      "metadata": {
        "id": "8rjWsBFbt2Vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directories for\n",
        "\n",
        "filename = \"knee_seg_sample.csv\"\n",
        "directory = \"KneeSample\"\n",
        "zipfile = \"knee_sample.zip\"\n",
        "\n",
        "classes = {\n",
        "    0: \"Background\",\n",
        "    1: \"R Patella\",\n",
        "    2: \"R Femur\",\n",
        "    3: \"R Tibia\",\n",
        "    4: \"R Fibula\",\n",
        "    5: \"L Patella\",\n",
        "    6: \"L Femur\",\n",
        "    7: \"L Tibia\",\n",
        "    8: \"L Fibula\"\n",
        "}\n",
        "\n",
        "zipfile_loc = f\"/content/drive/MyDrive/GoogleColabProjects/EBAIC_2024/KneeDataset/{zipfile}\"\n",
        "data_location = f\"/content/data/{directory}/{filename}\"\n",
        "data_save_location = f\"/content/data/{directory}/\""
      ],
      "metadata": {
        "id": "bc8qVtmMsRB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M9YCLP7atBq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(data_save_location):\n",
        "    with ZipFile(zipfile_loc, 'r') as zipf:\n",
        "        zipf.extractall(\"/content/\")"
      ],
      "metadata": {
        "id": "p3ZWmq51susS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_train_test_split(csv_pth, filter_query=None):\n",
        "    data_records = pd.read_csv(csv_pth)\n",
        "    data_records = data_records[data_records.id != 9025994].reset_index(drop=True)\n",
        "    if filter_query:\n",
        "        data_records = data_records.query(filter_query)\n",
        "\n",
        "    train, test = train_test_split(data_records.id.unique(), test_size=0.3, random_state=42)\n",
        "    valid, test = train_test_split(test, test_size=0.5, random_state=42)\n",
        "\n",
        "    train = data_records[data_records.id.isin(train)].reset_index(drop=True)\n",
        "    valid = data_records[data_records.id.isin(valid)].reset_index(drop=True)\n",
        "    test = data_records[data_records.id.isin(test)].reset_index(drop=True)\n",
        "\n",
        "    return train, valid, test"
      ],
      "metadata": {
        "id": "e2Qwhgqysxrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def balance_dataset(data, by_filter1, by_filter2):\n",
        "    filtered1 = data.query(by_filter1)\n",
        "    filtered2 = data.query(by_filter2)\n",
        "\n",
        "    min_sample_size = np.minimum(len(filtered1), len(filtered2))\n",
        "    samp1 = filtered1.sample(min_sample_size,  random_state = 42)\n",
        "    samp2 = filtered2.sample(min_sample_size,  random_state = 42)\n",
        "\n",
        "    balanced_data = pd.concat([samp1, samp2]).reset_index(drop=True)\n",
        "\n",
        "    print(f\"Training dataset reduced from size of {len(data)} samples to a balanced dataset of size {len(balanced_data)} samples\")\n",
        "\n",
        "    return balanced_data"
      ],
      "metadata": {
        "id": "eagrBr6TtHxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Baseline Datasets\n",
        "train_all, valid_all, test_all = generate_train_test_split(data_location)\n",
        "train_white, valid_white, test_white = generate_train_test_split(data_location, filter_query=\"P02RACE == '1: White or Caucasian'\")\n",
        "train_black, valid_black, test_black = generate_train_test_split(data_location, filter_query=\"P02RACE == '2: Black or African American'\")\n",
        "train_male, valid_male, test_male = generate_train_test_split(data_location, filter_query=\"P02SEX == '1: Male'\")\n",
        "train_female, valid_female, test_female = generate_train_test_split(data_location, filter_query=\"P02SEX == '2: Female'\")\n",
        "\n",
        "balanced_gender_train = balance_dataset(train_all, \"P02SEX == '1: Male'\", \"P02SEX == '2: Female'\")\n",
        "balanced_race_train = balance_dataset(train_all, \"P02RACE == '1: White or Caucasian'\", \"P02RACE == '2: Black or African American'\")"
      ],
      "metadata": {
        "id": "G1e695BotJZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Modeling\n",
        "In this section, we develop and train a set of segmentations models using a variaty of bias mitigation techiques, including:\n",
        "\n",
        "- Baseline\n",
        "- Group Specific (based on protected attributes)\n",
        "- Balanced\n",
        "- Stratified\n"
      ],
      "metadata": {
        "id": "e5F0R7TyR3kM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Baseline Models\n",
        "Models trained on the entire training dataset, ensuring that the distribution of the protected attributes, such as sex and race, accurately represent the entire dataset.\n"
      ],
      "metadata": {
        "id": "ZFxmkKsot_9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BonyAnatomyJointSegmentationDataset(Dataset):\n",
        "    def __init__(self, root_dir, ids, num_classes, transforms=None, preprocessing=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.pids = ids\n",
        "        self.num_classes = num_classes\n",
        "        self.transforms = transforms\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def load_dicom(self, path):\n",
        "        dicom_img = pydicom.dcmread(path)\n",
        "        return dicom_img.pixel_array.astype(np.float32)\n",
        "\n",
        "    def load_nii(self, path):\n",
        "        nii_annot = nibabel.load(path)\n",
        "        nii_annot_data = nii_annot.get_fdata()\n",
        "\n",
        "        if len(nii_annot_data.shape) == 3 and nii_annot_data.shape[-1] > 1:\n",
        "            if nii_annot_data.shape[-1] == 2:\n",
        "                nii_annot_data = nii_annot_data[:, :, 1]\n",
        "            else:\n",
        "                nii_annot_data = nii_annot_data[:, :, nii_annot_data.shape[-1]//2]\n",
        "\n",
        "            nii_annot_data = np.expand_dims(nii_annot_data, axis=-1)\n",
        "\n",
        "\n",
        "        nii_annot_data = cv2.rotate(nii_annot_data, cv2.ROTATE_90_CLOCKWISE)\n",
        "        nii_annot_data = cv2.flip(nii_annot_data, 1)\n",
        "        return nii_annot_data\n",
        "\n",
        "    def get_file_path(self, filename):\n",
        "        return os.path.join(self.root_dir, filename)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        image = self.load_dicom(self.get_file_path(os.path.join(\"Images/\", str(self.pids[idx]) + \".dcm\")))\n",
        "        mask = self.load_nii(self.get_file_path(os.path.join(\"Annotations\", str(self.pids[idx]) + \".nii.gz\")))\n",
        "\n",
        "#         if len(np.unique(mask)) != self.num_classes:\n",
        "#             print(self.pids[idx])\n",
        "        if self.transforms is not None:\n",
        "            transformed = self.transforms(image=image, mask=mask)\n",
        "            image = transformed[\"image\"]\n",
        "            mask = transformed[\"mask\"]\n",
        "        if self.preprocessing is not None:\n",
        "            transformed = self.preprocessing(image=image, mask=mask)\n",
        "            image = transformed[\"image\"]\n",
        "            mask = transformed[\"mask\"]\n",
        "\n",
        "        return image.type(torch.FloatTensor), mask.long()\n"
      ],
      "metadata": {
        "id": "RoQs24RmuUKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_loader, valid_loader, num_classes=9):\n",
        "    encoder = \"resnet18\"\n",
        "    encoder_weights = \"imagenet\"\n",
        "    activation = None\n",
        "\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model = copy.deepcopy(smp.Unet(encoder_name=encoder, encoder_weights=encoder_weights, in_channels=1,\n",
        "                    classes=num_classes, activation=activation)).to(device)\n",
        "    model.encoder.requires_grad_ = False\n",
        "    model.decoder.requires_grad_ = False\n",
        "\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    loss.__name__=\" loss\"\n",
        "\n",
        "    multi_jaccard = MulticlassJaccardIndex(num_classes=num_classes, average=\"macro\").to(device)\n",
        "    multi_jaccard.__name__ = \"iou_score\"\n",
        "    metrics = [multi_jaccard]\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-04)\n",
        "\n",
        "    # create epoch runners\n",
        "    # it is a simple loop of iterating over dataloader`s samples\n",
        "    train_epoch = smp.utils.train.TrainEpoch(\n",
        "        model,\n",
        "        loss=loss,\n",
        "        metrics=metrics,\n",
        "        optimizer=optimizer,\n",
        "        device=device,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "    valid_epoch = smp.utils.train.ValidEpoch(\n",
        "        model,\n",
        "        loss=loss,\n",
        "        metrics=metrics,\n",
        "        device=device,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "    max_score = 0\n",
        "\n",
        "    for i in range(1, 51):\n",
        "\n",
        "        print('\\nEpoch: {}'.format(i))\n",
        "        train_logs = train_epoch.run(train_loader)\n",
        "        valid_logs = valid_epoch.run(valid_loader)\n",
        "\n",
        "        # do something (save model, change lr, etc.)\n",
        "        if max_score < valid_logs['iou_score']:\n",
        "            max_score = valid_logs['iou_score']\n",
        "            torch.save(model, './best_model.pth')\n",
        "            print('Model saved!')\n",
        "\n",
        "    # Return best model\n",
        "    model = torch.load('./best_model.pth')\n",
        "    return model"
      ],
      "metadata": {
        "id": "EvQi5plPvfu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, test_loader, class_labels):\n",
        "    model.eval()\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    fig, ax = plt.subplots(nrows=5, ncols=3, figsize=(10, 10), sharex=True, sharey=True)\n",
        "\n",
        "    x, y = next(iter(test_loader))\n",
        "    out = torch.softmax(model(x.to(device)), dim=1)\n",
        "    #out = out.detach().cpu().numpy()\n",
        "\n",
        "    for i, pred in enumerate(out):\n",
        "        uni_channels = torch.argmax(pred, dim=0).unique()\n",
        "        pred = pred.detach().cpu().numpy()\n",
        "        ax[i][0].imshow(x[i].squeeze(), cmap=\"gray\")\n",
        "        yi = y[i].squeeze()\n",
        "        ax[i][1].imshow(yi)\n",
        "\n",
        "        # Merge predicted masks into one image\n",
        "        mask = np.where(pred[uni_channels[0].item(),:,:] > 0.5, uni_channels[0].item(), 0)\n",
        "        for channel in uni_channels[1:]:\n",
        "            channel = channel.item()\n",
        "            channel_mask = np.where(pred[channel,:,:] > 0.5, channel, 0)\n",
        "            mask = mask | channel_mask\n",
        "        ax[i][2].imshow(mask)\n",
        "\n",
        "    ax[0][0].set_title(\"Image\")\n",
        "    ax[0][1].set_title(\"Ground Truth Mask\")\n",
        "    ax[0][2].set_title(\"Predicted Mask\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    multi_jaccard = MulticlassJaccardIndex(num_classes=num_classes, average=\"none\").cuda()\n",
        "    multi_jaccard.__name__ = \"iou\"\n",
        "    metrics = [multi_jaccard]\n",
        "\n",
        "    results = torch.zeros((1, num_classes))\n",
        "    for x, y in test_loader:\n",
        "        results += multi_jaccard(torch.softmax(model(x.cuda()), dim=1), y.cuda()).detach().cpu()\n",
        "\n",
        "    results = results/len(test_loader)\n",
        "\n",
        "    for i in range(0, len(class_labels)):\n",
        "        print(f\"{class_labels[i]} (Class {i}): {results[0][i]}\")\n",
        "\n",
        "    print(f\"Mean Testing IoU: {multi_jaccard(torch.softmax(model(x.cuda()), dim=1), y.cuda()).mean()}\")\n",
        "    return results"
      ],
      "metadata": {
        "id": "RNCMcoGoycz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmentations = A.Compose([A.Resize(256, 256), ToTensorV2()])\n",
        "\n",
        "num_classes = 9"
      ],
      "metadata": {
        "id": "hGkOhTeavO0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = BonyAnatomyJointSegmentationDataset(data_save_location, train_all.id, num_classes,\n",
        "                                                transforms=augmentations)\n",
        "\n",
        "valid_set = BonyAnatomyJointSegmentationDataset(data_save_location, valid_all.id, num_classes,\n",
        "                                                transforms=augmentations)\n",
        "\n",
        "test_set = BonyAnatomyJointSegmentationDataset(data_save_location,test_all.id, num_classes,\n",
        "                                               transforms=augmentations)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=16, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_set, batch_size=16, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=5, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "MQExnRzVu0oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = train_model(train_loader, valid_loader, num_classes)"
      ],
      "metadata": {
        "id": "4xu2HCYrvLFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results = test_model(baseline_model, test_loader, classes)"
      ],
      "metadata": {
        "id": "XNJqSHp8xM5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Group Specific: Gender\n",
        "\n",
        "Models that are tailored to each gender group (e.g., female or male) to enhance the performance of the minority group.\n"
      ],
      "metadata": {
        "id": "-WhVqAY60fmQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Male"
      ],
      "metadata": {
        "id": "T-jqMABZ01F4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = BonyAnatomyJointSegmentationDataset(data_save_location, train_male.id, num_classes,\n",
        "                                                transforms=augmentations)\n",
        "\n",
        "valid_set = BonyAnatomyJointSegmentationDataset(data_save_location, valid_male.id, num_classes,\n",
        "                                                transforms=augmentations)\n",
        "\n",
        "test_set = BonyAnatomyJointSegmentationDataset(data_save_location, test_male.id, num_classes,\n",
        "                                               transforms=augmentations)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=16, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_set, batch_size=16, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=5, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "zIHKRcCNy3Xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_male_model = train_model(train_loader, valid_loader, num_classes)"
      ],
      "metadata": {
        "id": "6dggejIa0uuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_male_results = test_model(baseline_male_model, test_loader, classes)"
      ],
      "metadata": {
        "id": "Pz6FoGG90xJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Female"
      ],
      "metadata": {
        "id": "Qkz8__yN0xmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = BonyAnatomyJointSegmentationDataset(data_save_location, train_female.id, num_classes,\n",
        "                                                transforms=augmentations)\n",
        "\n",
        "valid_set = BonyAnatomyJointSegmentationDataset(data_save_location, valid_female.id, num_classes,\n",
        "                                                transforms=augmentations)\n",
        "\n",
        "test_set = BonyAnatomyJointSegmentationDataset(data_save_location, test_female.id, num_classes,\n",
        "                                               transforms=augmentations)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=16, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_set, batch_size=16, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=5, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "D0vm6ojw0yXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_female_model = train_model(train_loader, valid_loader, num_classes)"
      ],
      "metadata": {
        "id": "s2ixgt2b07tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_female_results = test_model(baseline_female_model, test_loader, classes)"
      ],
      "metadata": {
        "id": "Wk-QFFOw086q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Group Specific: Race\n",
        "\n",
        "Models that are tailored to each racial group (e.g., White/Caucasian or Black/African American) to enhance the performance of the minority group.\n"
      ],
      "metadata": {
        "id": "LcQL6vUu1C3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### White/Caucasian"
      ],
      "metadata": {
        "id": "V09lqyWf1DT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = BonyAnatomyJointSegmentationDataset(data_save_location, train_white.id, num_classes,\n",
        "                                                transforms=augmentations)\n",
        "\n",
        "valid_set = BonyAnatomyJointSegmentationDataset(data_save_location, valid_white.id, num_classes,\n",
        "                                                transforms=augmentations)\n",
        "\n",
        "test_set = BonyAnatomyJointSegmentationDataset(data_save_location, test_white.id, num_classes,\n",
        "                                               transforms=augmentations)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=16, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_set, batch_size=16, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=5, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "z887u24L1JMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_white_model = train_model(train_loader, valid_loader, num_classes)"
      ],
      "metadata": {
        "id": "bsxG9HiF1QwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_white_results = test_model(baseline_white_model, test_loader, classes)"
      ],
      "metadata": {
        "id": "pgR51Z971S-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Black/African American (AA)"
      ],
      "metadata": {
        "id": "OOK8OSj11Vu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = BonyAnatomyJointSegmentationDataset(data_save_location, train_black.id, num_classes,\n",
        "                                                transforms=augmentations)\n",
        "\n",
        "valid_set = BonyAnatomyJointSegmentationDataset(data_save_location, valid_black.id, num_classes,\n",
        "                                                transforms=augmentations)\n",
        "\n",
        "test_set = BonyAnatomyJointSegmentationDataset(data_save_location, test_black.id, num_classes,\n",
        "                                               transforms=augmentations)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=16, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_set, batch_size=16, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=5, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "-QSA1noA1Y3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_black_model = train_model(train_loader, valid_loader, num_classes)"
      ],
      "metadata": {
        "id": "L-I6xBZU1ig-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_black_results = test_model(baseline_black_model, test_loader, classes)"
      ],
      "metadata": {
        "id": "h_gFVgU41iZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Balanced Models\n",
        "\n",
        "Addresses potential bias and improvement of the modelâ€™s ability to accurately classify different\n",
        "examples from the underrepresented groups through under-sampling of the overrepresented protected groups in the\n",
        "training data. This approach aims to mitigate the risk of the model exhibiting bias towards majority groups and\n",
        "improve the ability to accurately classify the minority groups."
      ],
      "metadata": {
        "id": "WmQ4A8Qb1mM7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gender"
      ],
      "metadata": {
        "id": "KQqJShEY1t61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = BonyAnatomyJointSegmentationDataset(data_save_location, balanced_gender_train.id, num_classes,\n",
        "                                                transforms=augmentations)\n",
        "\n",
        "valid_set = BonyAnatomyJointSegmentationDataset(data_save_location, valid_all.id, num_classes,\n",
        "                                                transforms=augmentations)\n",
        "\n",
        "test_set = BonyAnatomyJointSegmentationDataset(data_save_location, test_all.id, num_classes,\n",
        "                                               transforms=augmentations)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=16, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_set, batch_size=16, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=5, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "7Ga9bXQW1su1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_gender_model = train_model(train_loader, valid_loader, num_classes)"
      ],
      "metadata": {
        "id": "pQ7qvroD2G42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_gender_results = test_model(balanced_gender_model, test_loader, classes)"
      ],
      "metadata": {
        "id": "WUMufBhS2K5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Race"
      ],
      "metadata": {
        "id": "tB8QGCGp2NVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = BonyAnatomyJointSegmentationDataset(data_save_location, balanced_race_train.id, num_classes,\n",
        "                                                transforms=augmentations)\n",
        "\n",
        "valid_set = BonyAnatomyJointSegmentationDataset(data_save_location, valid_all.id, num_classes,\n",
        "                                                transforms=augmentations)\n",
        "\n",
        "test_set = BonyAnatomyJointSegmentationDataset(data_save_location, test_all.id, num_classes,\n",
        "                                               transforms=augmentations)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=16, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_set, batch_size=16, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=5, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "XS4EVpNL2OUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_race_model = train_model(train_loader, valid_loader, num_classes)"
      ],
      "metadata": {
        "id": "0U_inJpS2Qn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_race_results = test_model(balanced_race_model, test_loader, classes)"
      ],
      "metadata": {
        "id": "s7hT7Ue62ScL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stratified Models\n",
        "\n",
        "Ensure that protected groups of interest have a balanced representation during training by grouping examples based on the protected attributes and then randomly sampling\n",
        "instances from each group. This creates mini-batches for training that have an unbiased distribution of examples for each protected group in every training batch."
      ],
      "metadata": {
        "id": "qYzD99KV2Tlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "class StratifiedSampler:\n",
        "    \"\"\"\n",
        "    Based on this Pytorch discussion board post\n",
        "    https://discuss.pytorch.org/t/how-to-enable-the-dataloader-to-sample-from-each-class-with-equal-probability/911/6\n",
        "    \"\"\"\n",
        "    def __init__(self, stratify_on, batch_size):\n",
        "        self.stratify_on = stratify_on\n",
        "        self.batch_size = batch_size\n",
        "        self.nsplits = int(len(stratify_on) / batch_size)\n",
        "\n",
        "    def gen_stratified_sample(self):\n",
        "        s = StratifiedKFold(n_splits = self.nsplits)\n",
        "\n",
        "        X = np.arange(0, len(self.stratify_on))\n",
        "        s.get_n_splits(X, self.stratify_on)\n",
        "        for train_idx, valid_idx in s.split(X, self.stratify_on):\n",
        "            yield valid_idx\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.gen_stratified_sample())\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.nsplits\n"
      ],
      "metadata": {
        "id": "gqcwHfWU2fIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gender"
      ],
      "metadata": {
        "id": "qfO8Zcmn2V6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = BonyAnatomyJointSegmentationDataset(data_save_location, train_all.id, num_classes,\n",
        "                                                transforms=augmentations)\n",
        "\n",
        "valid_set = BonyAnatomyJointSegmentationDataset(data_save_location, valid_all.id, num_classes,\n",
        "                                                transforms=augmentations)\n",
        "\n",
        "test_set = BonyAnatomyJointSegmentationDataset(data_save_location,test_all.id, num_classes,\n",
        "                                               transforms=augmentations)\n",
        "\n",
        "train_loader = DataLoader(train_set, num_workers=2, batch_sampler=StratifiedSampler(train_all.P02SEX, batch_size=16))\n",
        "valid_loader = DataLoader(valid_set, batch_size=16, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=5, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "QcXW9oX-2U3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stratified_gender_model = train_model(train_loader, valid_loader, num_classes)"
      ],
      "metadata": {
        "id": "_iUzuAmK27ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stratified_gender_results = test_model(stratified_gender_model, test_loader, classes)"
      ],
      "metadata": {
        "id": "rkw-yitS2-iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Race"
      ],
      "metadata": {
        "id": "APvSw5Te3BJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = BonyAnatomyJointSegmentationDataset(data_save_location, train_all.id, num_classes,\n",
        "                                                transforms=augmentations)\n",
        "\n",
        "valid_set = BonyAnatomyJointSegmentationDataset(data_save_location, valid_all.id, num_classes,\n",
        "                                                transforms=augmentations)\n",
        "\n",
        "test_set = BonyAnatomyJointSegmentationDataset(data_save_location,test_all.id, num_classes,\n",
        "                                               transforms=augmentations)\n",
        "\n",
        "train_loader = DataLoader(train_set, num_workers=2, batch_sampler=StratifiedSampler(train_all.P02RACE, batch_size=16))\n",
        "valid_loader = DataLoader(valid_set, batch_size=16, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=5, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "pNhGw92A3CDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stratified_race_model = train_model(train_loader, valid_loader, num_classes)"
      ],
      "metadata": {
        "id": "0V-vHw8B3Eq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stratified_race_results = test_model(stratified_race_model, test_loader, classes)"
      ],
      "metadata": {
        "id": "wnQhEyzv3H1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Model Evaluation using Intersection over Union (IoU)\n",
        "\n",
        "We evaluate each model by calcuating the Intersection over Union (IoU) across each protected group. IoU is defined as the area of overlap divided by the union of the two segmentation masks.\n",
        "\n",
        "![iou_equation.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "7wLJyTBiIUcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_bias(model, dataset, metric, num_classes = 9):\n",
        "    results = torch.zeros((1, num_classes))\n",
        "    test_loader = generate_dataloader(dataset, num_classes)\n",
        "    for x, y in test_loader:\n",
        "        results += metric(torch.softmax(model(x.cuda()), dim=1), y.cuda()).detach().cpu()\n",
        "\n",
        "    return results/len(test_loader)\n",
        "\n",
        "def generate_dataloader(dataset, num_classes):\n",
        "    augmentations = A.Compose([A.Resize(256, 256), ToTensorV2()]) # A.OneOf([A.Emboss(), Canny()\n",
        "    test_set = BonyAnatomyJointSegmentationDataset(data_save_location, dataset.id, num_classes,\n",
        "                                                   transforms=augmentations)\n",
        "    test_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "    return test_loader"
      ],
      "metadata": {
        "id": "XW7id1fHI3n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_jaccard = MulticlassJaccardIndex(num_classes=9, average=\"none\").cuda()\n",
        "multi_jaccard.__name__ = \"iou\""
      ],
      "metadata": {
        "id": "S9tiKIDKJBeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_records = pd.read_csv(data_location)"
      ],
      "metadata": {
        "id": "PtSiyDvEIjxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "male_group = data_records[data_records.P02SEX == \"1: Male\"].reset_index(drop=True)\n",
        "female_group = data_records[data_records.P02SEX == \"2: Female\"].reset_index(drop=True)\n",
        "white_caucasian_group = data_records[data_records.P02RACE == \"1: White or Caucasian\"].reset_index(drop=True)\n",
        "black_aa_group = data_records[data_records.P02RACE == \"2: Black or African American\"].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "5dViCGL1IWOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Baseline Models"
      ],
      "metadata": {
        "id": "1445uVxuSo9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gender_male_metrics_baseline = eval_bias(baseline_model, male_group, multi_jaccard)\n",
        "gender_female_metrics_baseline = eval_bias(baseline_model, female_group, multi_jaccard)\n",
        "race_white_metrics_baseline = eval_bias(baseline_model, white_caucasian_group, multi_jaccard)\n",
        "race_black_metrics_baseline = eval_bias(baseline_model, black_aa_group, multi_jaccard)\n",
        "\n",
        "base_dict = {\n",
        "    \"Gender: Male\": gender_male_metrics_baseline.numpy().squeeze(),\n",
        "    \"Gender: Female\": gender_female_metrics_baseline.numpy().squeeze(),\n",
        "    \"Race: White/Caucasian\": race_white_metrics_baseline.numpy().squeeze(),\n",
        "    \"Race: Black/AA\": race_black_metrics_baseline.numpy().squeeze(),\n",
        "}\n",
        "\n",
        "baseline_res = pd.DataFrame(base_dict).T\n",
        "baseline_res[\"Average\"] = baseline_res.mean(axis=1)\n",
        "baseline_res.columns = [val for key, val in classes.items()] + [\"Average\"]\n",
        "baseline_res"
      ],
      "metadata": {
        "id": "B6-6QFQlIwQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Balanced Models"
      ],
      "metadata": {
        "id": "mfUbgOYjSrh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gender_male_metrics_balanced = eval_bias(balanced_gender_model, male_group, multi_jaccard)\n",
        "gender_female_metrics_balanced = eval_bias(balanced_gender_model, female_group, multi_jaccard)\n",
        "\n",
        "balanced_gender = {\n",
        "    \"Gender: Male\": gender_male_metrics_balanced.numpy().squeeze(),\n",
        "    \"Gender: Female\": gender_female_metrics_balanced.numpy().squeeze(),\n",
        "}\n",
        "balanced_gender_res = pd.DataFrame(balanced_gender).T\n",
        "balanced_gender_res[\"Average\"] =  balanced_gender_res.mean(axis=1)\n",
        "balanced_gender_res.columns = [val for key, val in classes.items()] + [\"Average\"]\n",
        "\n",
        "balanced_gender_res"
      ],
      "metadata": {
        "id": "b0N3EhkmKFjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "race_white_metrics_balanced = eval_bias(balanced_race_model, white_caucasian_group, multi_jaccard)\n",
        "race_black_metrics_balanced = eval_bias(balanced_race_model, black_aa_group, multi_jaccard)\n",
        "\n",
        "balanced_race = {\n",
        "     \"Race: White/Caucasian\": race_white_metrics_balanced.numpy().squeeze(),\n",
        "    \"Race: Black/AA\": race_black_metrics_balanced.numpy().squeeze(),\n",
        "}\n",
        "balanced_race_res = pd.DataFrame(balanced_race).T\n",
        "balanced_race_res[\"Average\"] = balanced_race_res.mean(axis=1)\n",
        "balanced_race_res.columns = [val for key, val in classes.items()] + [\"Average\"]\n",
        "\n",
        "balanced_race_res"
      ],
      "metadata": {
        "id": "Xm6YQ9RkKV5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stratified Models"
      ],
      "metadata": {
        "id": "sjvp39QuSugU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gender_male_metrics_stratified = eval_bias(stratified_gender_model, male_group, multi_jaccard)\n",
        "gender_female_metrics_stratified = eval_bias(stratified_gender_model, female_group, multi_jaccard)\n",
        "\n",
        "strat_gender = {\n",
        "    \"Gender: Male\": gender_male_metrics_stratified.numpy().squeeze(),\n",
        "    \"Gender: Female\": gender_female_metrics_stratified.numpy().squeeze(),\n",
        "}\n",
        "strat_gender_res = pd.DataFrame(strat_gender).T\n",
        "strat_gender_res[\"Average\"] = strat_gender_res.mean(axis=1)\n",
        "strat_gender_res.columns = [val for key, val in classes.items()] + [\"Average\"]\n",
        "strat_gender_res"
      ],
      "metadata": {
        "id": "UY0j5j6zK_yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "race_white_metrics_stratified = eval_bias(stratified_race_model, white_caucasian_group, multi_jaccard)\n",
        "race_black_metrics_stratified= eval_bias(stratified_race_model, black_aa_group, multi_jaccard)\n",
        "\n",
        "strat_race = {\n",
        "    \"Race: White/Caucasian\": race_white_metrics_stratified.numpy().squeeze(),\n",
        "    \"Race: Black/AA\": race_black_metrics_stratified.numpy().squeeze(),\n",
        "}\n",
        "strat_race_res = pd.DataFrame(strat_race).T\n",
        "strat_race_res[\"Average\"] = strat_race_res.mean(axis=1)\n",
        "strat_race_res.columns = [val for key, val in classes.items()] + [\"Average\"]\n",
        "strat_race_res"
      ],
      "metadata": {
        "id": "Xd-7qEYTK3EI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Group Specific Models"
      ],
      "metadata": {
        "id": "5ENL2aPZSyD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gender_male_metrics = eval_bias(baseline_male_model, male_group, multi_jaccard)\n",
        "\n",
        "gender_male = {\n",
        "    \"Gender: Male\": gender_male_metrics.numpy().squeeze(),\n",
        "}\n",
        "gender_male = pd.DataFrame(gender_male).T\n",
        "gender_male[\"Average\"] = gender_male.mean(axis=1)\n",
        "gender_male.columns = [val for key, val in classes.items()] + [\"Average\"]\n",
        "gender_male"
      ],
      "metadata": {
        "id": "6X_5WxHmLKTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gender_female_metrics = eval_bias(baseline_female_model, female_group, multi_jaccard)\n",
        "\n",
        "gender_female = {\n",
        "    \"Gender: Female\": gender_female_metrics.numpy().squeeze(),\n",
        "}\n",
        "gender_female = pd.DataFrame(gender_female).T\n",
        "gender_female[\"Average\"] = gender_female.mean(axis=1)\n",
        "gender_female.columns = [val for key, val in classes.items()] + [\"Average\"]\n",
        "gender_female"
      ],
      "metadata": {
        "id": "8wxnEBqRLUyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "race_white_metrics = eval_bias(baseline_white_model, white_caucasian_group, multi_jaccard)\n",
        "\n",
        "race_white = {\n",
        "    \"Race: White/Caucasian\": race_white_metrics.numpy().squeeze(),\n",
        "}\n",
        "race_white = pd.DataFrame(race_white).T\n",
        "race_white[\"Average\"] = race_white.mean(axis=1)\n",
        "race_white.columns = [val for key, val in classes.items()] + [\"Average\"]\n",
        "race_white"
      ],
      "metadata": {
        "id": "Lf31YIEZLcEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "race_black_metrics = eval_bias(baseline_black_model, black_aa_group, multi_jaccard)\n",
        "\n",
        "race_black = {\n",
        "    \"Race: Black/AA\": race_black_metrics.numpy().squeeze(),\n",
        "}\n",
        "race_black = pd.DataFrame(race_black).T\n",
        "race_black[\"Average\"] = race_black.mean(axis=1)\n",
        "race_black.columns = [val for key, val in classes.items()] + [\"Average\"]\n",
        "race_black"
      ],
      "metadata": {
        "id": "pNeHkyERLpNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Fairness Evaluation\n",
        "\n",
        "To evaluate fairness, we utilize the Skewed Error Ratio (SER), which focuses specifically on evaluating potential biases in the algorithmâ€™s prediction errors toward specific groups. SER, is defined as:\n",
        "\n",
        "\n",
        "$$SER_{g}= \\frac{Max_g (1 - IoU_g)}{Min_g ( 1- IoU_g)}\n",
        "$$\n",
        "\n",
        "\n",
        "It utilizes the ratio of highest to lowest error rate among protected groups, with $g$ denoting the considered protected groups. Higher values of SER present a higher presence of bias, while values closer to one are an indication of a lower presence of bias.\n"
      ],
      "metadata": {
        "id": "tzeM8aghSYaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_fairness_score(data):\n",
        "    sd = []\n",
        "    ser = []\n",
        "\n",
        "    for i, row in data.iterrows():\n",
        "        sd.append(row[1:].std())\n",
        "        min_group = row[1:].min()\n",
        "        max_group = row[1:].max()\n",
        "        ser.append((1 - min_group)/(1 - max_group))\n",
        "\n",
        "    return sd, ser"
      ],
      "metadata": {
        "id": "R_DvIH88L5WB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gender"
      ],
      "metadata": {
        "id": "uJx5N5Y9Sceh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fairness_gender = {\n",
        "    \"Model\": [\"Baseline\", \"Balanced\", \"Stratified\", \"Group-Specific\"],\n",
        "    \"Male\": [baseline_res.loc[\"Gender: Male\", \"Average\"],\n",
        "             balanced_gender_res.loc[\"Gender: Male\", \"Average\"],\n",
        "             strat_gender_res.loc[\"Gender: Male\", \"Average\"],\n",
        "             gender_male.loc[\"Gender: Male\", \"Average\"]],\n",
        "    \"Female\":[baseline_res.loc[\"Gender: Female\", \"Average\"],\n",
        "             balanced_gender_res.loc[\"Gender: Female\", \"Average\"],\n",
        "             strat_gender_res.loc[\"Gender: Female\", \"Average\"],\n",
        "             gender_female.loc[\"Gender: Female\", \"Average\"]]\n",
        "}\n",
        "\n",
        "fairness_df_gender = pd.DataFrame(fairness_gender)\n",
        "sd, ser = calc_fairness_score(fairness_df_gender)\n",
        "fairness_df_gender[\"SD\"] = sd\n",
        "fairness_df_gender[\"SER\"] = ser\n",
        "\n",
        "fairness_df_gender"
      ],
      "metadata": {
        "id": "ozSgh74AMA20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Race"
      ],
      "metadata": {
        "id": "xVeknCuzShO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fairness_race = {\n",
        "    \"Model\": [\"Baseline\", \"Balanced\", \"Stratified\", \"Group-Specific\"],\n",
        "    \"White/Caucasian\": [baseline_res.loc[\"Race: White/Caucasian\", \"Average\"],\n",
        "             balanced_race_res.loc[\"Race: White/Caucasian\", \"Average\"],\n",
        "             strat_race_res.loc[\"Race: White/Caucasian\", \"Average\"],\n",
        "             race_white.loc[\"Race: White/Caucasian\", \"Average\"]],\n",
        "    \"Black/African American\":[baseline_res.loc[\"Race: Black/AA\", \"Average\"],\n",
        "             balanced_race_res.loc[\"Race: Black/AA\", \"Average\"],\n",
        "             strat_race_res.loc[\"Race: Black/AA\", \"Average\"],\n",
        "             race_black.loc[\"Race: Black/AA\", \"Average\"]]\n",
        "}\n",
        "\n",
        "fairness_df_race = pd.DataFrame(fairness_race)\n",
        "sd, ser = calc_fairness_score(fairness_df_race)\n",
        "fairness_df_race[\"SD\"] = sd\n",
        "fairness_df_race[\"SER\"] = ser\n",
        "\n",
        "fairness_df_race"
      ],
      "metadata": {
        "id": "PFAyOnhAMEN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ANz0PcXYNmsB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}